
#+TITLE: Homework 2
#+AUTHOR: Bray Moll
#+OPTIONS: toc:nil
#+SETUPFILE: ~/masters/bray-standard-latex-export.org
#+ATTR_LATEX: :options frame=single :float nil

* Exercise 1
*** Given:
The wine.csv dataset provided on Canvas
how would this look if i updated this 
*** Find:
a) Estimate the quality of the wine on the 17th row using a k = 3 \\
b) Estimate the quality of the wine on the 17th row using a k = 15 \\
c) Find the actual value for quality and determine which value of k produced a better output \\
*** Solution
#+NAME: Load Data Set
#+ATTR_LATEX: :options frame=single
#+BEGIN_SRC R :results value :exports code :session homework-2 :colnames yes
  rm(list=ls())
  setwd("~/masters/computational-statistics/hw")
  library(caret)
  library(ggplot2)

  # Load the wine dataset 
  wine_dataset = read.csv("./hw2/wine.csv")
  summary(wine_dataset)
#+END_SRC

#+RESULTS: Load Data Set
| fixed.acidity  | volatile.acidity | citric.acid    | residual.sugar | chlorides       | free.sulfur.dioxide | total.sulfur.dioxide | density        | pH            | sulphates      | alcohol       | quality       |
|----------------+------------------+----------------+----------------+-----------------+---------------------+----------------------+----------------+---------------+----------------+---------------+---------------|
| Min.   : 3.800 | Min.   :0.0800   | Min.   :0.0000 | Min.   : 0.600 | Min.   :0.00900 | Min.   :  2.00      | Min.   :  9.0        | Min.   :0.9871 | Min.   :2.720 | Min.   :0.2200 | Min.   : 8.00 | Min.   :3.000 |
| 1st Qu.: 6.300 | 1st Qu.:0.2100   | 1st Qu.:0.2700 | 1st Qu.: 1.700 | 1st Qu.:0.03600 | 1st Qu.: 23.00      | 1st Qu.:108.0        | 1st Qu.:0.9917 | 1st Qu.:3.090 | 1st Qu.:0.4100 | 1st Qu.: 9.50 | 1st Qu.:5.000 |
| Median : 6.800 | Median :0.2600   | Median :0.3200 | Median : 5.200 | Median :0.04300 | Median : 34.00      | Median :134.0        | Median :0.9937 | Median :3.180 | Median :0.4700 | Median :10.40 | Median :6.000 |
| Mean   : 6.855 | Mean   :0.2782   | Mean   :0.3342 | Mean   : 6.391 | Mean   :0.04577 | Mean   : 35.31      | Mean   :138.4        | Mean   :0.9940 | Mean   :3.188 | Mean   :0.4898 | Mean   :10.51 | Mean   :5.878 |
| 3rd Qu.: 7.300 | 3rd Qu.:0.3200   | 3rd Qu.:0.3900 | 3rd Qu.: 9.900 | 3rd Qu.:0.05000 | 3rd Qu.: 46.00      | 3rd Qu.:167.0        | 3rd Qu.:0.9961 | 3rd Qu.:3.280 | 3rd Qu.:0.5500 | 3rd Qu.:11.40 | 3rd Qu.:6.000 |
| Max.   :14.200 | Max.   :1.1000   | Max.   :1.6600 | Max.   :65.800 | Max.   :0.34600 | Max.   :289.00      | Max.   :440.0        | Max.   :1.0390 | Max.   :3.820 | Max.   :1.0800 | Max.   :14.20 | Max.   :9.000 |




#+NAME: Scale Data Set
#+ATTR_LATEX: :options frame=single
#+BEGIN_SRC R :results none :exports code :session homework-2 :wrap latex
    # Scale the features of the data set to have a standard deviation of 1 
    wine_dataset[,1:(ncol(wine_dataset)-1)] =
      scale(wine_dataset[,1:(ncol(wine_dataset)-1)])

    # split data set into training and test datasets
    wine_dataset.train <- wine_dataset[-17,]
    wine_dataset.test <- wine_dataset[17,]
#+END_SRC


#+NAME: fit model
#+ATTR_LATEX: :options frame=single
#+BEGIN_SRC R :results output :exports both :session homework-2

  for(k_list in c(3,15)){
    knn.fit <- knnreg(
      wine_dataset.train[,(1:ncol(wine_dataset.train)-1)],
      wine_dataset.train[,ncol(wine_dataset.train)],
      k=k_list
    )
    pred_y <- predict(knn.fit, wine_dataset.test[,(1:ncol(wine_dataset.test)-1)])
    print(sprintf("With %d neighbors a quality of %f is predicted",k_list,pred_y))

  }



  test.quality <- wine_dataset.test[,ncol(wine_dataset.test)]
  sprintf("The actual quality for the 17th row is %d", test.quality)
#+END_SRC

#+RESULTS: fit model
: [1] "With 3 neighbors a quality of 4.666667 is predicted"
: [1] "With 15 neighbors a quality of 4.937500 is predicted"
: [1] "The actual quality for the 17th row is 6"

Based on these results, the model with 15 neighbors had the better
prediction.

\newpage
* Excersise 2 
** Given:
The Dataset shown (default from ISLR2)
** Find:
a) Filter the dataset so that only students are remaining \\
b) Plot balance against income. Can you deduce anything from the plot?\\
c) Using the k-nn algorithm, clasify a test instance of income 18000 and balance = 1900 with k =11\\
d) Using the k-nn algorithm, clasify a test instance of income 18000 and balance = 1900 with k =55
e) Considering parts c) and d) which model is more flexible, which will have a higher bias, which will have a higher varaince?
** Solution:
*** a)
#+NAME: Exersise 2 Load data
#+ATTR_LATEX: :options frame=single
#+BEGIN_SRC R :results output :exports both :session hw2-excersise-2 :colnames yes
                          rm(list=ls())
                          setwd("~/masters/computational-statistics/hw/hw2")
                          library(caret)
                          library(ggplot2)
                          library(ISLR2)
                          library(dplyr)
                          data(Default)
                          studentonly <- Default %>% filter(student == "Yes")
                          summary(studentonly)
                          head(studentonly)

#+END_SRC

#+RESULTS: Exersise 2 Load data
#+begin_example
 default    student       balance           income     
 No :2817   No :   0   Min.   :   0.0   Min.   :  772  
 Yes: 127   Yes:2944   1st Qu.: 655.6   1st Qu.:14887  
                       Median : 980.0   Median :17994  
                       Mean   : 987.8   Mean   :17950  
                       3rd Qu.:1303.9   3rd Qu.:20986  
                       Max.   :2654.3   Max.   :33003
  default student   balance    income
1      No     Yes  817.1804 12106.135
2      No     Yes  919.5885  7491.559
3      No     Yes  808.6675 17600.451
4      No     Yes    0.0000 21871.073
5      No     Yes 1220.5838 13268.562
6      No     Yes  527.5402 17636.540
#+end_example



*** b)
#+NAME: Exersise 2 Plot Data
#+ATTR_LATEX: :options frame=single
#+BEGIN_SRC R :results graphics file :file myplot.png :exports both :session hw2-excersise-2
  myplot <- ggplot(studentonly, aes(x= income, y = balance, color = default)) +
    geom_point() +
  labs(
    x = "income",
    y = "balance",
    color = "Default"

  )
  plot_save <- ggsave("myplot.png", plot = myplot)
#+END_SRC

#+RESULTS: Exersise 2 Plot Data
[[file:myplot.png]]

based on this we can deduce that for the student subset of the dataset
the balance is corelated with the default rates while the income of
the student subset does not seem to be strongly corelated. We can also
observe that the default rate is low when the balance is under
$1000. Also of note is that the "no" classification is much more
common than the "yes" clasification.

*** c) and d)

#+NAME: Exersise 2 Prepare Datset
#+ATTR_LATEX: :options frame=single
#+BEGIN_SRC R :results output :exports both :session hw2-excersise-2 :colnames yes

  feature_columns <- c("income", "balance")
  # Create a new dataframe with just the labels recoded into a -1 or 1
  studentonly.labels <- data.frame(
    default = ifelse(studentonly$default == "Yes", 1, -1)
  )
  studentonly.features <- studentonly[ , feature_columns]

  #pre-processing.
  #Note centering is not needed for knn but was included for future flexibility
  preprocess <- preProcess(studentonly.features, method =c("center", "scale"))

  studentonly.features.scaled <- predict(preprocess, studentonly.features)
  summary(studentonly.features)
  summary(studentonly.features.scaled)

  #create the test features and then scale them as well
  studentonly.test.features <- data.frame(income = 18000, balance = 1900)
  studentonly.test.features.scaled <- predict(preprocess, studentonly.test.features)
  studentonly.test.features
  studentonly.test.features.scaled
  summary(studentonly.labels$default)

#+END_SRC
This shows the input features ranging from 772-33003 for income and
0-2654.3 for balance before scaling. After scaling we are centered
around 0. The test features were scaled using the same standard
deviation (and mean) used to scale the trainining features. For
clasification the labels were recoded to a -1 for "no" and a 1 for
"yes". 
 #+RESULTS: Exersise 2 Prepare Datset
 #+begin_example
      income         balance      
  Min.   :  772   Min.   :   0.0  
  1st Qu.:14887   1st Qu.: 655.6  
  Median :17994   Median : 980.0  
  Mean   :17950   Mean   : 987.8  
  3rd Qu.:20986   3rd Qu.:1303.9  
  Max.   :33003   Max.   :2654.3
      income             balance        
  Min.   :-3.789595   Min.   :-2.04555  
  1st Qu.:-0.675795   1st Qu.:-0.68798  
  Median : 0.009661   Median :-0.01621  
  Mean   : 0.000000   Mean   : 0.00000  
  3rd Qu.: 0.669699   3rd Qu.: 0.65455  
  Max.   : 3.320795   Max.   : 3.45097
   income balance
 1  18000    1900
       income  balance
 1 0.01097929 1.888928
    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 -1.0000 -1.0000 -1.0000 -0.9137 -1.0000  1.0000
 #+end_example


#+NAME: Exersise 2 Fit model
#+ATTR_LATEX: :options frame=single
#+BEGIN_SRC R :results output :exports both :session hw2-excersise-2

  for(k_list in c(1:11,55)){
    knn_fit <- knnreg(studentonly.features.scaled,studentonly.labels$default,k=k_list)
    pred_y <- ifelse(
      predict(knn_fit,studentonly.test.features.scaled ) >= 0, "yes", "no"
    )
    print(sprintf("With %d neighbors, the prediction is %s",k_list, pred_y))

  }
#+END_SRC

#+RESULTS: Exersise 2 Fit model
#+begin_example
[1] "With 1 neighbors, the prediction is yes"
[1] "With 2 neighbors, the prediction is yes"
[1] "With 3 neighbors, the prediction is yes"
[1] "With 4 neighbors, the prediction is yes"
[1] "With 5 neighbors, the prediction is yes"
[1] "With 6 neighbors, the prediction is yes"
[1] "With 7 neighbors, the prediction is no"
[1] "With 8 neighbors, the prediction is no"
[1] "With 9 neighbors, the prediction is no"
[1] "With 10 neighbors, the prediction is no"
[1] "With 11 neighbors, the prediction is no"
[1] "With 55 neighbors, the prediction is no"
#+end_example

Both predictions with k=11 and k =55 predict a "no" for defaulting at
an income level of 18000 and balance of 1900. As an exersise the
neigbors was explored from 1 to 11 and the predcition switched from
yes to a no after the number of neighbors was increased beyond 6.

*** e)
The model using a  lower number of neighbors would be the more
flexible model with a lower bias but higher varaince

* Testing with org mode and exporting
Now we can do some testing. If i want to *bold* a word i can add
asterisks to the end.

If i want to italicise /you can *surround it in forward slash's* like i
have on this/

\begin{equation}
x=\sqrt{b}
\end{equation}

